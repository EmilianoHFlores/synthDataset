# -*- coding: utf-8 -*-
"""YOLO_SAM_autolabel_multiple.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v1iu8aQ-F8uVBcj8-fXuRE6_s1urObMa
"""
# Commented out IPython magic to ensure Python compatibility.
# %cd segment-anything/notebooks
import os
import torch
import cv2
import os
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path

pathtoimage = "soap"
resultspath = "resultsSoap"
if not os.path.exists(resultspath):
  os.makedirs(resultspath)
cutobject = "soap"
print("Will be checking images in: ", pathtoimage)
# Model
#model = torch.hub.load("ultralytics/yolov5", "yolov5l")  # or yolov5n - yolov5x6, custom
model = torch.hub.load("ultralytics/yolov5", 'custom', "yolo11classes.pt", force_reload=True)

import sys
sys.path.append("..")
from segment_anything import sam_model_registry, SamPredictor
sam_model = "h"

#wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth
if sam_model =="h":
  sam_checkpoint = "sam_vit_h_4b8939.pth"
  model_type = "vit_h"
else:
  sam_checkpoint = "sam_vit_l_0b3195.pth"
  model_type = "vit_l"

device = "cuda"

sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
sam.to(device=device)

predictor = SamPredictor(sam)

# Creating annotation in COCO format
#{"id": 0, "file_name": "0.jpg", "height": 480, "width": 736}
images=[]
annotations=[]
categories=[]

image_0 ={"id": 0, "file_name": "0.jpg", "height": 480, "width": 736}

img_id=0
anno_id=0

#check if results directory exists, else create it
if not os.path.exists(resultspath):
  os.makedirs(resultspath)


imgPaths = os.listdir(pathtoimage)
print(imgPaths)

i=0

for imgPath in imgPaths:
  print(f"Processing image: {imgPath}")
  img = cv2.imread(f"{pathtoimage}/{imgPath}")
  if img is None:
    continue
  #results = model(img)
  results = model(pathtoimage+'/'+imgPath)

  image_bboxes = []
  xywh = []

  #Get yolo results
  for *xyxy, conf, cls in results.pandas().xyxy[0].itertuples(index=False):
    #run for each detection
    ran_sam = False
    if cls in ['zote']: #What objects we want to cut
      category_id = 0 if cls=='cup' else 1
      print(f"Predicted {cls} at {[round(elem, 2) for elem in xyxy ]} with on img {imgPath}.")
      image_bbox = (np.array([xyxy[0], xyxy[1], xyxy[2], xyxy[3]]))
      xywh = [xyxy[0], xyxy[1], xyxy[2]-xyxy[0], xyxy[3]-xyxy[1]]

      #run sam
      if ran_sam == False:
        predictor.set_image(img)
        ran_sam = True
  
      mask, _, _ = predictor.predict(
          point_coords=None,
          point_labels=None,
          box=image_bbox,
          multimask_output=False,
      )

      contours, _ = cv2.findContours(mask[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Your call to find the contours
      # threshold input image using otsu thresholding as mask and refine with morphology
      ret, pngmask = cv2.threshold(mask[0].astype(np.uint8), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU) 
      kernel = np.ones((9,9), np.uint8)
      pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_CLOSE, kernel)
      pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_OPEN, kernel)

      # put mask into alpha channel of result
      result = img.copy()
      result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)
      result[:, :, 3] = pngmask
      #cv2.imwrite(f"{resultspath}/{cutobject}_{i}.png", result)
      #to save with same name as original file
      # if already exists, save with _1, _2, etc
      if os.path.exists(f"{resultspath}/{imgPath[:-4]}.png"):
        if os.path.exists(f"{resultspath}/{imgPath[:-4]}_1.png"):
          print("File already exists, saving with _2")
          cv2.imwrite(f"{resultspath}/{imgPath[:-4]}_2.png", result)
        print("File already exists, saving with _1")
        cv2.imwrite(f"{resultspath}/{imgPath[:-4]}_1.png", result)

      cv2.imwrite(f"{resultspath}/{imgPath[:-4]}.png", result)
      i=i+1
  ran_sam = False
